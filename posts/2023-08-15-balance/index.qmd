---
title: "Detecting Data Falsification with Machine Learning"
description: |
  A simple, fast, and powerful tool for detecting data falsification in experimental designs.  
author:
  - name: Jack T. Rametta 
    url: https://jackrametta.com
    orcid: 0000-0002-9841-146X
date: 2023-08-16
citation: 
  url: https://cetialphafive.github.io/jrametta/posts/2023-08-12-balance/
categories: [experiments, ML, causal inference, MLbalance]
bibliography: references.bib
#image: conformal.preview.png
draft: true
---

Fraudulent academic research is an unfortunate, persistent issue.

For example, there are several [recent](https://datacolada.org/109) [cases](https://datacolada.org/110) [of data](https://datacolada.org/111) [falsification](https://datacolada.org/112) from a Harvard psychologist who I, uh, won't name here (please excuse my cowardice, I enjoy not being involved in litigation). These cases of falsification were uncovered by the sleuths at [Data Colada](https://datacolada.org/), who desire serious credit for their investigative work, and for weathering the legal flack.

What these cases leave me wondering is **what can we do about it?**

One part of the solution is making fraud easier to detect. To that end, we need tools for fraud detection that don't require Colada level forensic skills.[^1]

[^1]: Seriously, I was a hardcore excel user for the first several years of my career and I had no idea you could use CalcChain files like that! 



In the rest of this post I outline what my co-author Sam Fuller and I call the Balance Permutation Test.

This test leverages a common feature of falsified experimental data: the treatment assignment isn't exogenous (as it of course should be!). Put another way, in many cases of falsified experimental data, treatment assignment can be deterministically predicted using other measured covariates. So what we propose is simple: try to model treatment assignment as a function of covariates measured in the experiment

This tool was developed with the original intention of detecting accidental, or chance, imbalance in experimental designs, but it works just as well for detecting intentional

Simple tools for detecting fraud that could be employed at any stage of the review, or replication, process can disincentivize
